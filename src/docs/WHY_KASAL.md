# Why Kasal - Available on Databricks Marketplace

Transform your Databricks environment into an AI orchestration powerhouse. Build intelligent agent workflows that unlock the full potential of your Databricks lakehouse - now available directly in the Databricks Marketplace for one-click installation.

---

## The Problem We Solve

Your organization has invested in Databricks for data and AI, but building intelligent workflows still requires extensive coding. Teams struggle to connect AI capabilities to their data in Unity Catalog. Manual processes don't leverage your lakehouse investment.

Kasal bridges this gap - making Databricks AI capabilities accessible to everyone.

---

## What Makes Kasal Different

### Visual Agent Design
Drag and drop AI agents onto a canvas. Connect them like building blocks. No code required.

Each agent has a role:
- Research Agent: Gathers information from databases and documents
- Analysis Agent: Processes data and finds patterns
- Writer Agent: Creates reports and summaries
- Decision Agent: Makes choices based on rules you define

### Real Data Connection - Powered by Databricks
Connect directly to your Databricks ecosystem and beyond:
- **Databricks Native**: Query Unity Catalog, Delta Lake, SQL Warehouses
- **Databricks Volumes**: Store and access knowledge documents
- **Databricks Vector Search**: Semantic search across your data
- **Files**: Read PDFs, Excel, CSV, JSON, XML files
- **Documents**: Process Word docs, presentations, text files
- **APIs**: Connect to Salesforce, HubSpot, custom endpoints
- **Knowledge**: Upload documents to Databricks for AI-powered search

### Intelligent Collaboration
Agents work together like a team:
- One agent's output becomes another's input
- Parallel processing for independent tasks
- Sequential flows for dependent operations
- Conditional routing based on results

---

## Real Use Cases in Production

### Financial Analysis with Databricks
**Setup**: 3 agents leveraging your lakehouse
- Data Agent queries Unity Catalog tables with SQL
- Analysis Agent uses Databricks ML for anomaly detection
- Report Agent generates executive summary from Delta Lake

**Result**: 4-hour manual process reduced to 5 minutes, all within Databricks

### Customer Support with Databricks Knowledge
**Setup**: Databricks-powered response system
- Store documentation in Databricks Volumes
- Agent uses Vector Search for semantic understanding
- Query customer history from Delta tables
- Escalates complex issues with full context

**Result**: 80% of inquiries handled automatically using your Databricks data

### Research and Intelligence on Lakehouse
**Setup**: Databricks-native information synthesis
- Web Search Agent finds latest market data
- Unity Catalog Agent queries your governed data
- ML Agent leverages Databricks models for analysis
- Presentation Agent creates slides from insights

**Result**: Weekly research that took 2 days now takes 30 minutes, integrated with your lakehouse

---

## How It Actually Works

### 1. Design Your Workflow
Open the visual designer. Drag agents onto the canvas. Each agent represents a worker with specific skills.

### 2. Configure Each Agent
Tell agents what to do in plain language:
- "Search the sales database for Q4 revenue"
- "Analyze this data and find the top 3 trends"
- "Write a summary suitable for the board meeting"

### 3. Connect Your Databricks Resources
Point agents to your lakehouse assets:
- Unity Catalog tables and views
- Databricks SQL warehouses
- Delta Lake tables
- Databricks Volumes for documents
- Vector indexes for semantic search

### 4. Run and Monitor
Press start. Watch agents work in real-time. See their thinking process. Review outputs before they're sent.

---

## The Technology Under the Hood - Databricks Native

### Databricks Apps Platform
Kasal runs natively on Databricks Apps:
- **OAuth Authentication**: Secure user authentication with Databricks identity
- **On-Behalf-Of (OBO)**: Execute operations with user permissions
- **Workspace Integration**: Direct access to your Databricks workspace
- **Native Deployment**: One-click installation from Databricks Marketplace

### Databricks Data Access
Direct integration with your lakehouse:
- **Unity Catalog**: Query governed data with SQL
- **Delta Lake**: Read and write Delta tables
- **SQL Warehouses**: Execute queries on compute resources
- **Databricks SQL**: Full SQL support for data operations

### Databricks AI & ML
Leverage Databricks AI capabilities:
- **Model Serving**: Use Databricks-hosted models (DBRX, Llama, MPT)
- **Vector Search**: Semantic search across documents and data
- **Databricks Volumes**: Store and access knowledge documents
- **MLflow Integration**: Track and deploy ML models

### Databricks-Specific Tools
Purpose-built for your lakehouse:
- **Genie Tool**: Natural language queries against your data
- **Databricks SQL Tool**: Direct SQL execution on warehouses
- **Unity Catalog Tool**: Access governed data assets
- **Vector Search Tool**: Semantic knowledge retrieval
- **Databricks Jobs Tool**: Orchestrate and monitor jobs

### Enterprise Features
Leveraging Databricks security:
- **Workspace Isolation**: Multi-tenant with group separation
- **Secret Management**: Databricks secret scopes for credentials
- **Audit Logging**: Full audit trail in Databricks
- **Permission Model**: Honors Databricks ACLs and permissions

---

## Getting Started with Databricks Marketplace

### One-Click Installation
**Install directly from Databricks Marketplace**:
1. Open Databricks Marketplace in your workspace
2. Search for "Kasal"
3. Click "Get" - automatic installation begins
4. Launch Kasal from your Databricks Apps

### Minute 1: Choose a Template
Pick from Databricks-optimized workflows:
- Unity Catalog Data Pipeline
- Lakehouse Analytics Flow
- Delta Lake Processing
- ML Model Orchestration

### Minute 2: Automatic Databricks Connection
No configuration needed:
- Inherits your Databricks permissions
- Accesses your Unity Catalog automatically
- Connects to your SQL warehouses
- Uses your workspace identity

### Minute 3: Customize for Your Data
Point to your lakehouse assets:
- Select Unity Catalog tables
- Choose Delta Lake sources
- Configure SQL queries
- Set processing rules

### Minute 4: Run Your First Workflow
- Press execute
- Agents query your Databricks data
- Monitor in real-time
- Results stay in your lakehouse

### Minute 5: Deploy in Databricks
- Schedule with Databricks Jobs
- Monitor through Databricks UI
- Scale with SQL warehouses
- Integrate with existing pipelines

---

## Who Benefits from Kasal

### Data Teams on Databricks
Query Unity Catalog without writing SQL. Build Delta Lake pipelines visually. Generate dashboards automatically from your lakehouse data.

### Analytics Teams
Transform raw data in Unity Catalog into insights. Automate report generation from Delta tables. Schedule complex analytical workflows.

### ML Engineers
Orchestrate model training on Databricks compute. Chain ML models into production pipelines. Monitor and retrain automatically.

### Business Users
Access governed data through natural language. Build workflows that leverage your organization's data. Get answers from your lakehouse instantly.

---

## Integration Capabilities - Databricks First

### Native Databricks Integration
- **Unity Catalog**: Full access to governed data
- **Delta Lake**: Read/write Delta tables directly
- **SQL Warehouses**: Execute queries on your compute
- **Databricks Volumes**: Store documents and files
- **Vector Search**: Semantic search across your data
- **Model Serving**: Use Databricks-hosted AI models

### File Formats in Databricks
Process files stored in Volumes:
- PDF documents
- Excel spreadsheets
- CSV data files
- JSON/XML structures
- Word documents
- Parquet files

### Additional Connectivity
Extend beyond Databricks when needed:
- REST APIs with authentication
- External databases via JDBC
- Webhook receivers
- Custom integrations via MCP

### AI Models on Databricks
Leverage Databricks Model Serving:
- **Llama 4 Maverick**: Latest Meta foundation model
- **Llama 3.3 70B**: Multi-language with 128K context
- **Llama 3.1 405B**: Largest open model, GPT-4 competitive
- **GPT OSS 120B**: OpenAI's reasoning model
- **Claude on Databricks**: Anthropic models via Foundation APIs
- **Custom Models**: Your MLflow models

---

## Licensing

Kasal is available under the **Databricks License** through the Databricks Marketplace.

### What This Means for You
- **Free to install** from Databricks Marketplace
- **Usage-based pricing** through your existing Databricks consumption
- **No separate subscription** - runs on your Databricks compute
- **Enterprise support** through Databricks

### Cost Structure
- **Compute costs**: Standard Databricks SQL Warehouse pricing
- **Storage costs**: Standard Databricks storage rates for Volumes
- **Model costs**: Pay-per-token for AI models used
- **No additional licensing fees** for Kasal itself

---

## Success Metrics

Teams using Kasal report:
- **75% reduction** in manual data processing
- **10x faster** report generation
- **90% accuracy** in routine decisions
- **50% cost savings** vs custom development

---

## Start Building Today on Databricks

1. **Find Kasal in Databricks Marketplace**
2. **One-click installation to your workspace**
3. **Build your first workflow in minutes**
4. **See immediate results with your data**

Transform how your team leverages the Databricks Data Intelligence Platform.

---

*Kasal: Unleashing the full potential of Databricks for everyone*